{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42807e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from osgeo import gdal\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df871088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_divide(a, b):\n",
    "    return np.divide(a, b, out=np.zeros_like(a), where=b != 0)\n",
    "\n",
    "class Landsat_Dataset(object):\n",
    "\n",
    "    # 使用data_analysis/data_analysis.py的calculate_mean_std()计算得到\n",
    "    mean = np.array([961.8782, 1053.7188, 1302.2211, 1573.1169, 2185.5655, 2097.9481, 1643.7379])\n",
    "    std = np.array([362.9614, 395.8249, 512.3208, 599.7623, 769.1146, 734.0038, 645.0721])\n",
    "\n",
    "    class_info = {    # 标注信息\n",
    "        \"shaqiu\": 1,\n",
    "        \"xintan\": 2,\n",
    "        \"gengdi\": 3,\n",
    "        \"building\": 4,\n",
    "        \"water\": 5,\n",
    "        \"veg\": 6\n",
    "    }\n",
    "    n_class = len(class_info.items())\n",
    "\n",
    "    def __init__(self, dataset_dir, alpha=0.3, random_seed=2024):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.val_rate = alpha\n",
    "        self.rand_seed = random_seed\n",
    "        self.train_set, self.val_set = self._load_dataset()\n",
    "        self.train_data_len = len(self.train_set)\n",
    "        self.valid_data_len = len(self.val_set)\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        fids = [f for f in os.listdir(os.path.join(self.dataset_dir, 'images')) if f[-4:] == \".tif\"]\n",
    "        class_sets = defaultdict(list)\n",
    "        # 读取数据并按类别收集样本\n",
    "        for f in fids:\n",
    "            img, _, _ = read_gdal(os.path.join(self.dataset_dir, 'images', f))\n",
    "            label, _, _ = read_gdal(os.path.join(self.dataset_dir, 'labels', f))\n",
    "            assert img.shape[0:2] == label.shape[0:2], \"样本数据中影像和标签栅格行列数必须一致\"\n",
    "\n",
    "            h, w, c = img.shape\n",
    "            img = img.reshape((h*w, c))\n",
    "            label = label.reshape((-1))\n",
    "            for cls_name in self.class_info.keys():\n",
    "                _indexes = (label == self.class_info[cls_name])\n",
    "                _data = img[_indexes]\n",
    "                class_sets[cls_name].extend(list(_data))\n",
    "        \n",
    "        if self.rand_seed is not None:\n",
    "            random.seed(self.rand_seed)\n",
    "            \n",
    "        if True:\n",
    "            negative_num = len(class_sets['target']) * 10\n",
    "            _list = class_sets['others'].copy()\n",
    "            class_sets['others'] = random.sample(_list, negative_num)\n",
    "\n",
    "        # 每个类别按统一比例分为训练/验证样本数据\n",
    "        train_set = defaultdict(list)\n",
    "        val_set = defaultdict(list)\n",
    "        print(\"{:<15} {:<10} {:<10}\".format(\"class\", \"train\", \"val\"))\n",
    "        for cls_name, cls_id in self.class_info.items():\n",
    "            _data = class_sets[cls_name]\n",
    "            _total_num = len(_data)\n",
    "            random.shuffle(_data)\n",
    "            _train_num = int(_total_num * (1 - self.val_rate))\n",
    "            _train_data = _data[:_train_num]\n",
    "            _val_data = _data[_train_num:]\n",
    "            train_set[cls_name].extend(_train_data)\n",
    "            val_set[cls_name].extend(_val_data)\n",
    "            print(\"{:<15} {:<10d} {:<10d}\".format(cls_name, len(_train_data), len(_val_data)))\n",
    "        return train_set, val_set\n",
    "\n",
    "    @classmethod\n",
    "    def Normalize(cls, img_data):\n",
    "        return (img_data - cls.mean) / cls.std\n",
    "\n",
    "    @classmethod\n",
    "    def NDWI(cls, img_data):\n",
    "        # img_data (N, 7)\n",
    "        # NDWI: (G-NIR)/(G+NIR)\n",
    "        g = img_data[..., 2].astype(np.float32)\n",
    "        nir = img_data[..., 4].astype(np.float32)\n",
    "        ndwi = np_divide((g - nir), (g + nir))\n",
    "        return ndwi\n",
    "\n",
    "    @classmethod\n",
    "    def NDVI(cls, img_data):\n",
    "        # img_data (N, 7)\n",
    "        # NDVI: (NIR-R)/(NIR+R)\n",
    "        r = img_data[..., 3].astype(np.float32)\n",
    "        nir = img_data[..., 4].astype(np.float32)\n",
    "        ndvi = np_divide((nir - r), (nir + r))\n",
    "        return ndvi\n",
    "\n",
    "    @classmethod\n",
    "    def transform(cls, img_data, pca=None):\n",
    "        ndwi = cls.NDWI(img_data)\n",
    "        # ndvi = cls.NDVI(img_data)\n",
    "        data = cls.Normalize(img_data)\n",
    "        if pca is not None:\n",
    "            data = pca.transform(data)\n",
    "        data = np.concatenate([data, ndwi], axis=-1)\n",
    "        return data\n",
    "    \n",
    "    def get_class_feature(self, class_name=''):\n",
    "        if class_name in self.class_info:\n",
    "            train_data = self.train_set[class_name]\n",
    "            val_data = self.val_set[class_name]\n",
    "        return np.array(train_data + val_data)\n",
    "\n",
    "    def _get_samples(self, dataset, num_per_cls):\n",
    "        image_data = []\n",
    "        label_data = []\n",
    "        if self.rand_seed is not None:\n",
    "            random.seed(self.rand_seed)\n",
    "\n",
    "        tmp = []\n",
    "        for cls_name, cls_id in self.class_info.items():\n",
    "            cls_data = dataset[cls_name]\n",
    "            cls_label = list(np.ones(len(cls_data), np.uint8) * (cls_id - 1))\n",
    "            cls_samples = list(zip(cls_label, cls_data))\n",
    "            if num_per_cls is not None:\n",
    "                _num = min(num_per_cls, len(cls_samples))\n",
    "                cls_samples = random.sample(cls_samples, _num)\n",
    "            tmp.extend(cls_samples)\n",
    "        random.shuffle(tmp)\n",
    "\n",
    "        for label_item, data_item in tmp:\n",
    "            image_data.append(data_item)\n",
    "            label_data.append(label_item)\n",
    "\n",
    "        image_data, label_data = np.array(image_data), np.array(label_data)\n",
    "        return image_data, label_data\n",
    "\n",
    "    def get_train_set(self, num_per_cls=None):\n",
    "        ''' data for trainning '''\n",
    "        x_train, y_train = self._get_samples(self.train_set, num_per_cls)\n",
    "        return x_train, y_train\n",
    "\n",
    "    def get_val_set(self, num_per_cls=None):\n",
    "        ''' data for valuation '''\n",
    "        x_val, y_val = self._get_samples(self.val_set, num_per_cls)\n",
    "        return x_val, y_val\n",
    "    \n",
    "    \n",
    "def read_gdal(path):\n",
    "    image = gdal.Open(path)  # 打开该图像\n",
    "    if image == None:\n",
    "        print(path + \"文件无法打开\")\n",
    "        return\n",
    "    img_w = image.RasterXSize  # 栅格矩阵的列数\n",
    "    img_h = image.RasterYSize  # 栅格矩阵的行数\n",
    "    # im_bands = image.RasterCount  # 波段数\n",
    "    im_proj = image.GetProjection()  # 获取投影信息\n",
    "    im_geotrans = image.GetGeoTransform()  # 仿射矩阵\n",
    "    im_data = image.ReadAsArray(0, 0, img_w, img_h)\n",
    "    if len(im_data.shape) == 2:\n",
    "        im_data = im_data[np.newaxis, :, :]\n",
    "    im_data = im_data.transpose((1, 2, 0))\n",
    "    return im_data, im_proj, im_geotrans    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f16a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(image, nodata=None):\n",
    "    channel_num = image.shape[-1]\n",
    "    if nodata is not None:\n",
    "        nodata_mask = np.all(image==nodata, axis=-1)\n",
    "        image = image[~nodata_mask]\n",
    "    means, stdevs = [], []\n",
    "    for i in range(channel_num):\n",
    "        pixels = image[..., i].ravel()\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    return means, stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdecf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = dataset.get_train_set()\n",
    "x_val, y_val = dataset.get_val_set()\n",
    "data = np.concatenate([x_train, x_val], axis=0)\n",
    "calculate_mean_std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f5d856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1134, 1678, 7)\n"
     ]
    }
   ],
   "source": [
    "img, _, _ = read_gdal(r\"C:\\Users\\Admin\\Desktop\\HJN\\data\\image\\cut.tif\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30ec3580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [ 961.8782 1053.7188 1302.2211 1573.1169 2185.5655 2097.9481 1643.7379]\n",
      "std: [362.9614 395.8249 512.3208 599.7623 769.1146 734.0038 645.0721]\n"
     ]
    }
   ],
   "source": [
    "means, stdevs = calculate_mean_std(img)\n",
    "print('mean:', np.round(means, 4))\n",
    "print('std:', np.round(stdevs, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37206f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 961.8782, 1053.7188, 1302.2211, 1573.1169, 2185.5655, 2097.9481,\n",
       "       1643.7379])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(means, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f26bd06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([362.9614, 395.8249, 512.3208, 599.7623, 769.1146, 734.0038,\n",
       "       645.0721])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(stdevs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecf94659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class           train      val       \n",
      "shaqiu          667        286       \n",
      "xintan          7422       3181      \n",
      "gengdi          1071       459       \n",
      "building        625        268       \n",
      "water           2480       1063      \n",
      "veg             1026       441       \n"
     ]
    }
   ],
   "source": [
    "ld = Landsat_Dataset(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\HJN\\\\datasets\\\\v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c54db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch17",
   "language": "python",
   "name": "torch17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
